---
layout: post
comments: true
mathjax: true
priority: 440000
title: “Common information retrieval evaluation metrics”
tags: [information retrieval]
excerpt: information retrieval
img: ir.png
date: 2019-07-09 12:00:00
---

## Rank-Based Measures:

1. Binary relevance
* Precision@K (P@K)
* Mean Average Precision (MAP)
* Mean Reciprocal Rank (MRR)

2. Multiple levels of relevance
* Normalized Discounted Cumulative Gain (NDCG)

## Precision@K

1. Set a rank threshold K
2. Compute % relevant in top K
3. Ignores documents ranked lower than K
4. Example:

    * Prec@3 of 2/3
    * Prec@4 of 2/4
    * Prec@5 of 3/5

<div class="imgcap">
<img src="https://user-images.githubusercontent.com/22668421/60916015-5dbe7f80-a25b-11e9-9022-e1ebfd592b4e.png" style="border:none;width:100%">
</div>

   



  



