---
layout: post
comments: true
mathjax: true
priority: 440000
title: “Meta Learning --- Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks”
tags: [Machine Learning]
img: ml.png
excerpt: Machine Learning
date: 2019-05-01 12:00:00
---
## Intro
The goal of meta-learning is to train a model on a variety of learning tasks, such that it can solve new
learning tasks using only a small number of training samples. This algorithm can be directly applied to any learning problem and model that is trained with a gradient descent procedure. The key idea underlying this method is to train the model’s initial parameters such that the model has maximal performance on a new task after the parameters have been updated through one or more gradient steps computed with a small amount of data from that new task.

## Model-Agnostic Meta-Learning
1. **Meta-Learning Problem Set-Up**
In effect, the meta-learning problem treats entire tasks as training examples. We consider a model, denoted $$f$$, that maps observations $$x$$ to outputs $$a$$. During meta-learning, the model is trained to be able to adapt to a large or infinite number of tasks. Formally, each task $$\mathcal{T}=\left\{\mathcal{L}\left(\mathbf{x}_{1}, \mathbf{a}_{1}, \dots, \mathbf{x}_{H}, \mathbf{a}_{H}\right), q\left(\mathbf{x}_{1}\right),\\ q\left(\mathbf{x}_{t+1} | \mathbf{x}_{t}, \mathbf{a}_{t}\right), H\right\}$$ consists of a loss function $$\mathcal{L}$$, a distribution over initial observations $$q(x_{1})$$, a transition distribution $$q(x_{t+1}|x_{t}, a_{t})$$, and an episode length $$H$$.
In the meta-learning scenario, we consider a distribution over tasks $$p(T)$$ that we want our model to be able to adapt
to. In the K-shot learning setting, the model is trained to learn a new task $$T_{i}$$ drawn from $$p(T)$$ from only K samples drawn from $$q_{i}$$ and feedback $$L_{T_{i}}$$ generated by $$T_{i}$$. During meta-training, a task $$T_{i}$$ is sampled from $$p(T)$$, the model is trained with K samples and feedback from the corresponding loss $$L_{T_{i}}$$ from $$T_{i}$$.
2. **Why it is not training on test set**?
This is the biggest confusion that I had when  I first read this paper, but after read it in detail, it is not what I thought, In effect, the test error on sampled tasks $$T_{i}$$ serves as the training error of the meta-learning process. At the end of meta-training, new tasks are sampled from $$p(T)$$, and meta-performance is measured by the model’s performance after learning from K samples. Generally, tasks used for meta-testing are held out during meta-training.

3. **A Model-Agnostic Meta-Learning Algorithm**
Prior work has sought to train recurrent neural networks that ingest entire datasets. The author propose a method that can learn the parameters of any standard model via meta-learning in such a way as to prepare that model
for fast adaptation. The intuition behind this approach is that some internal representations are more transferrable
than others. For example, a neural network might learn internal features that are broadly applicable to all tasks in
$$p(T)$$, rather than a single individual task. In effect, we will aim to find model parameters that are sensitive to changes in the task, such that small changes in the parameters will produce large improvements on the loss function of any task drawn from $$p(T)$$, when altered in the direction of the gradient of that loss. We make no assumption on the form of the model, other than to assume that it is parametrized by some parameter vector $$θ$$, and that the loss function is smooth enough in θ that we can use gradient-based learning techniques.
<div class="imgcap">
<img src="https://user-images.githubusercontent.com/22668421/57057736-18893a80-6c79-11e9-88b8-bf46dcd82593.png" style="border:none;width:100%">
</div>

<div class="imgcap">
<img src="https://user-images.githubusercontent.com/22668421/57057772-44a4bb80-6c79-11e9-8f72-e7299ab89904.png" style="border:none;width:100%">
</div>

Formally, we consider a model represented by a parametrized function $$f_{θ}$$ with parameters $$θ$$. When adapting to a new task $$T_{i}$$, the model’s parameters $$θ$$ become $$θ^{\prime}_{i}$$. In our method, the updated parameter vector $$θ^{/prime}_{i}$$ is computedusing one or **more** gradient descent updates on task $$T_{i}$$. For example, when using one gradient update.
$$
\theta_{i}^{\prime}=\theta-\alpha \nabla_{\theta} \mathcal{L}_{\tau_{i}}\left(f_{\theta}\right)
$$

The model parameters are trained by optimizing for the performance of $$f_{θ^{\prime}_{i}}$$ with respect to θ across tasks sampled from $$p(T)$$. More concretely, the meta-objective is as follows:
$$
\min _{\theta} \sum_{\mathcal{T}_{i} \sim p(\mathcal{T})} \mathcal{L}_{\mathcal{T}_{i}}\left(f_{\theta_{i}^{\prime}}\right)=\sum_{\mathcal{T}_{i} \sim p(\mathcal{T})} \mathcal{L}_{\mathcal{T}_{i}}\left(f_{\theta-\alpha \nabla_{\theta} \mathcal{L}_{i}}\left(f_{\theta}\right)\right)
$$

The meta-optimization across tasks is performed via stochastic gradient descent (SGD), such that the model parameters $$θ$$ are updated as follows:
$$
\theta \leftarrow \theta-\beta \nabla_{\theta} \sum_{\mathcal{T}_{i} \sim p(\mathcal{T})} \mathcal{L}_{\mathcal{T}_{i}}\left(f_{\theta_{i}^{\prime}}\right)
$$
where $$β$$ is the meta step size

## Specific instantiations of MAML
1.  Supervised Regression and Classification
**Few-shot learning is well-studied in the domain of supervised tasks, where the goal is to learn a new function from only a few input/output pairs for that task**
For regression tasks using mean-squared error, the loss takes the form:
$$
\mathcal{L}_{\mathcal{T}_{i}}\left(f_{\phi}\right)=\sum_{\mathbf{x}^{(j)}, \\
\mathbf{y}^{(j)} \sim \mathcal{T}_{i}}\left\|f_{\phi}\left(\mathbf{x}^{(j)}\right)-\mathbf{y}^{(j)}\right\|_{2}^{2}<br>
$$ where $$ \mathbf{x}^{(j)}, \mathbf{y}^{(j)} $$. are an input/output pair sampled from task $$T_{i}$$. 
Similarly, for discrete classification tasks with a crossentropy loss, the loss takes the form:
$$
\begin{aligned} \mathcal{L}_{\mathcal{T}_{i}}\left(f_{\phi}\right)=& \sum_{\mathbf{x}^{(j)}, \mathbf{y}^{(j)} \sim \mathcal{T}_{i}} \mathbf{y}^{(j)} \log f_{\phi}\left(\mathbf{x}^{(j)}\right) \\ &+\left(1-\mathbf{y}^{(j)}\right) \log \left(1-f_{\phi}\left(\mathbf{x}^{(j)}\right)\right) \end{aligned}
$$

<div class="imgcap">
<img src="https://user-images.githubusercontent.com/22668421/57094595-eb6f7300-6cde-11e9-9352-5b42a7eb480c.png" style="border:none;width:100%">
</div>





